{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c65e1b86-9e64-49b2-ab63-fd05d16a23db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Palm Beach County road network...\n",
      "Downloading landuse polygons...\n",
      "Cleaning datasets...\n",
      "Joining traffic controls to edges...\n",
      "\n",
      "Extracted 493,737 nodes and 947,921 edges\n",
      "Traffic controls: 4,696 stops, 2,863 signals\n",
      "Landuse polygons: 1,829\n",
      "\n",
      "Bronze layer saved\n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "# Configure OSM tags\n",
    "ox.settings.useful_tags_node = ['highway', 'traffic_signals', 'stop', 'crossing', 'give_way']\n",
    "ox.settings.useful_tags_way = [\n",
    "    'highway', 'name', 'ref', 'lanes', 'maxspeed', 'oneway', \n",
    "    'bridge', 'tunnel', 'layer', 'junction',\n",
    "    'turn:lanes', 'surface', 'lit', 'width'\n",
    "]\n",
    "\n",
    "# Download network\n",
    "print(\"Downloading Palm Beach County road network...\") \n",
    "G = ox.graph_from_place(\"Palm Beach County, Florida, USA\", network_type=\"drive_service\", simplify=False) #simplify = false because we need the highest quantity of attributes, stop signs, yield, etc...\n",
    "G = ox.project_graph(G, to_crs=\"EPSG:26917\") \n",
    "nodes, edges = ox.graph_to_gdfs(G)\n",
    "nodes = nodes.reset_index() \n",
    "edges = edges.reset_index()\n",
    "\n",
    "print(\"Downloading landuse polygons...\")\n",
    "landuse_tags = {\"landuse\": [\"residential\", \"retail\", \"commercial\", \"industrial\", \n",
    "                            \"construction\", \"education\", \"institutional\", \"forest\"]}\n",
    "landuse_polys = ox.features_from_place(\"Palm Beach County, Florida, USA\", tags=landuse_tags)\n",
    "landuse_polys = landuse_polys.to_crs(\"EPSG:26917\")\n",
    "landuse_polys = landuse_polys.reset_index()\n",
    "\n",
    "# Flatten nested columns OSM sometimes returns lists\n",
    "def stringify_and_flatten(val):\n",
    "    if isinstance(val, (list, np.ndarray)):\n",
    "        return \"|\".join(map(str, val))\n",
    "    if isinstance(val, (int, float, np.integer, np.floating)):\n",
    "        return val\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    return str(val)\n",
    "\n",
    "skip = {'geometry', 'u', 'v', 'key', 'osmid'}\n",
    "\n",
    "def clean_osm_columns(df):\n",
    "    for col in df.columns:\n",
    "        if col in skip: \n",
    "            continue\n",
    "        df[col] = df[col].apply(stringify_and_flatten)\n",
    "        df[col] = df[col].astype(str).replace('nan', np.nan)\n",
    "    return df\n",
    "\n",
    "print(\"Cleaning datasets...\")\n",
    "nodes_clean = clean_osm_columns(nodes.copy())\n",
    "edges_clean = clean_osm_columns(edges.copy())\n",
    "landuse_polys = clean_osm_columns(landuse_polys)\n",
    "\n",
    "# Join traffic controls to road segments\n",
    "# OSM stores these as node attributes, but we need them on edges for analysis\n",
    "print(\"Joining traffic controls to edges...\")\n",
    "nodes['has_stop'] = (nodes['highway'] == 'stop').astype(int)\n",
    "nodes['has_signal'] = (nodes['highway'] == 'traffic_signals').astype(int)\n",
    "nodes['has_crossing'] = nodes['crossing'].notna().astype(int)\n",
    "nodes['has_give_way'] = (nodes['highway'] == 'give_way').astype(int)\n",
    "\n",
    "node_lookup = nodes.set_index('osmid')[['has_stop', 'has_signal', 'has_crossing', 'has_give_way']]\n",
    "\n",
    "# Map controls to both ends of each edge (u = start, v = end)\n",
    "edges_clean['OSM_has_stop_u'] = edges['u'].map(node_lookup['has_stop']).fillna(0).astype(int)\n",
    "edges_clean['OSM_has_signal_u'] = edges['u'].map(node_lookup['has_signal']).fillna(0).astype(int)\n",
    "edges_clean['OSM_has_crossing_u'] = edges['u'].map(node_lookup['has_crossing']).fillna(0).astype(int)\n",
    "edges_clean['OSM_has_give_way_u'] = edges['u'].map(node_lookup['has_give_way']).fillna(0).astype(int)\n",
    "\n",
    "edges_clean['OSM_has_stop_v'] = edges['v'].map(node_lookup['has_stop']).fillna(0).astype(int)\n",
    "edges_clean['OSM_has_signal_v'] = edges['v'].map(node_lookup['has_signal']).fillna(0).astype(int)\n",
    "edges_clean['OSM_has_crossing_v'] = edges['v'].map(node_lookup['has_crossing']).fillna(0).astype(int)\n",
    "edges_clean['OSM_has_give_way_v'] = edges['v'].map(node_lookup['has_give_way']).fillna(0).astype(int)\n",
    "\n",
    "edges_clean['has_stop_at_ends'] = (edges_clean['OSM_has_stop_u'] | edges_clean['OSM_has_stop_v']).astype(int)\n",
    "edges_clean['has_signal_at_ends'] = (edges_clean['OSM_has_signal_u'] | edges_clean['OSM_has_signal_v']).astype(int)\n",
    "edges_clean['has_crossing_at_ends'] = (edges_clean['OSM_has_crossing_u'] | edges_clean['OSM_has_crossing_v']).astype(int)\n",
    "edges_clean['has_give_way_at_ends'] = (edges_clean['OSM_has_give_way_u'] | edges_clean['OSM_has_give_way_v']).astype(int)\n",
    "\n",
    "print(f\"\\nExtracted {len(nodes):,} nodes and {len(edges):,} edges\")\n",
    "print(f\"Traffic controls: {nodes['has_stop'].sum():,} stops, {nodes['has_signal'].sum():,} signals\")\n",
    "print(f\"Landuse polygons: {len(landuse_polys):,}\")\n",
    "\n",
    "# Save to parquet\n",
    "nodes_clean.to_parquet(\"bronze_osm_nodes.parquet\")\n",
    "edges_clean.to_parquet(\"bronze_osm_network.parquet\")\n",
    "landuse_polys.to_parquet(\"bronze_osm_landuse.parquet\")\n",
    "print(\"\\nBronze layer saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18597db3-bf91-4437-8b55-c2ef24675c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Saved: aadt (1334 rows)\n",
      "Layer Saved: access_management (115 rows)\n",
      "Error extracting basemap_arcs: Invalid SQL query for layer 'b'basemap_arcs'': 'COUNTY = 'PALM BEACH' OR COUNTYDOT = '93''\n",
      "Layer Saved: basemap_route_road (1197 rows)\n",
      "Error extracting basemap_routes: Invalid SQL query for layer 'b'basemap_routes'': 'COUNTY = 'PALM BEACH' OR COUNTYDOT = '93''\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wizard/anaconda3/envs/ox/lib/python3.14/site-packages/pyogrio/raw.py:200: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured MultiLineString' is converted to 'MultiLineString'\n",
      "  return ogr_read(\n",
      "/home/wizard/anaconda3/envs/ox/lib/python3.14/site-packages/pyogrio/raw.py:200: UserWarning: Measured (M) geometry types are not supported. Original type 'Measured MultiLineString' is converted to 'MultiLineString'\n",
      "  return ogr_read(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Saved: bike_lane (2042 rows)\n",
      "Layer Saved: bike_slot (1644 rows)\n",
      "Layer Saved: box_culverts (18 rows)\n",
      "Layer Saved: bridges (542 rows)\n",
      "Layer Saved: county_roads (21 rows)\n",
      "Layer Saved: divided (589 rows)\n",
      "Layer Saved: faccross (371 rows)\n",
      "Layer Saved: fahwysys (1086 rows)\n",
      "Layer Saved: funclass (1142 rows)\n",
      "Layer Saved: hpms (118 rows)\n",
      "Layer Saved: inside_shoulder_type (3491 rows)\n",
      "Layer Saved: inside_shoulder_width (3017 rows)\n",
      "Layer Saved: interchange (45 rows)\n",
      "Layer Saved: intersection (16250 rows)\n",
      "Layer Saved: interstates (1 rows)\n",
      "Layer Saved: localnam (1334 rows)\n",
      "Layer Saved: maintenance_boundary (260 rows)\n",
      "Layer Saved: maxspeed (349 rows)\n",
      "Layer Saved: median_type (4487 rows)\n",
      "Layer Saved: median_width (4496 rows)\n",
      "Layer Saved: mpoarea (1250 rows)\n",
      "Layer Saved: national_highway_freight_network (10 rows)\n",
      "Layer Saved: national_network (3 rows)\n",
      "Layer Saved: nhs (61 rows)\n",
      "Layer Saved: number_of_lanes (5461 rows)\n",
      "Layer Saved: off_system (592 rows)\n",
      "Layer Saved: on_system (57 rows)\n",
      "Layer Saved: outside_shoulder_type (17543 rows)\n",
      "Layer Saved: outside_shoulder_width (17677 rows)\n",
      "Error extracting ptms: Invalid SQL query for layer 'b'ptms'': 'COUNTY = 'PALM BEACH' OR COUNTYDOT = '93''\n",
      "Layer Saved: railcross (127 rows)\n",
      "Layer Saved: ramps (197 rows)\n",
      "Layer Saved: rdaccess (596 rows)\n",
      "Layer Saved: REST_Welcome_FDOT (4 rows)\n",
      "Layer Saved: road_status (1258 rows)\n",
      "Layer Saved: roadway (1197 rows)\n",
      "Layer Saved: shared_path (387 rows)\n",
      "Layer Saved: sidewalk_barrier (6663 rows)\n",
      "Layer Saved: sidewalk_width_sep (7096 rows)\n",
      "Layer Saved: state_roads (59 rows)\n",
      "Layer Saved: surface_width (4364 rows)\n",
      "Layer Saved: surfnum (2705 rows)\n",
      "Layer Saved: toll_roads (1 rows)\n",
      "Layer Saved: traffic_signal_locations (648 rows)\n",
      "Layer Saved: truck_volume (1334 rows)\n",
      "Error extracting ttms: Invalid SQL query for layer 'b'ttms'': 'COUNTY = 'PALM BEACH' OR COUNTYDOT = '93''\n",
      "Layer Saved: typeroad (1317 rows)\n",
      "Layer Saved: us_roads (25 rows)\n",
      "Layer Saved: weigh_in_motion (4 rows)\n",
      "\n",
      "Bronze Extraction Complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "gdb_path = \"DOTShapesFGDB.gdb\"\n",
    "layers = gpd.list_layers(gdb_path)\n",
    "\n",
    "os.makedirs(\"bronze_fdot_layers\", exist_ok=True)\n",
    "fdot_metadata = []\n",
    "\n",
    "for layer_name in layers['name']:\n",
    "    try:\n",
    "        # County 93 is Palm Beach\n",
    "        query = \"COUNTY = 'PALM BEACH' OR COUNTYDOT = '93'\"\n",
    "        \n",
    "        df = gpd.read_file(\n",
    "            gdb_path, \n",
    "            layer=layer_name, \n",
    "            where=query, \n",
    "            engine='pyogrio'\n",
    "        )\n",
    "        \n",
    "        if not df.empty:\n",
    "            # we need it this way for the spatial join later on, it's not a big deal and can be converted to degrees in the silver layer. \n",
    "            df = df.to_crs(epsg=26917)\n",
    "            \n",
    "            file_path = f\"bronze_fdot_layers/{layer_name}.parquet\"\n",
    "            df.to_parquet(file_path)\n",
    "\n",
    "            # can sometimes miss the \"milepost\" not a big deal, we don't really need it. (x coordinate, y coordinate, m milepost metadata unecessary for the spatial join, it's for potholes and shit)\n",
    "            fdot_metadata.append({'layer': layer_name, 'count': len(df), 'path': file_path})\n",
    "            print(f\"Layer Saved: {layer_name} ({len(df)} rows)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting {layer_name}: {e}\")\n",
    "\n",
    "\n",
    "# to note, some of columns are missing, (basemap_routes, basemap_arcs). We don't need them because we are using OSM as our skeleton, making a new one from fdot would probably be hell.\n",
    "pd.DataFrame(fdot_metadata).to_parquet(\"bronze_fdot_manifest.parquet\", index=False)\n",
    "print(\"\\nBronze Extraction Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4a8e2f-62cf-4d13-8a01-faeeec5ec976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
